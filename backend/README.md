# Backend - Chatbot Reglamento de TrÃ¡nsito Hermosillo

API FastAPI para el chatbot de consulta del Reglamento de TrÃ¡nsito de Hermosillo 2025.

## ğŸš€ Inicio RÃ¡pido

### 1. Crear entorno virtual (recomendado)

```bash
python3 -m venv venv
source venv/bin/activate  # En macOS/Linux
# o
venv\Scripts\activate  # En Windows
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 3. (Opcional) Configurar Hugging Face LLM

Si quieres que el chatbot use inteligencia artificial en lugar de bÃºsqueda simple:

1. Crea una cuenta gratis en [Hugging Face](https://huggingface.co)
2. ObtÃ©n tu API key en: https://huggingface.co/settings/tokens
3. Crea un archivo `.env` en este directorio (backend/):

```bash
cp .env.example .env
```

4. Edita `.env` y agrega tu API key:

```
HUGGINGFACE_API_KEY=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

**Nota:** Sin la API key, el chatbot funcionarÃ¡ con bÃºsqueda inteligente en el JSON local.

### 4. Iniciar el servidor

```bash
uvicorn main:app --reload --port 8000
```

El servidor estarÃ¡ disponible en: `http://localhost:8000`

## ğŸ¤– Flujo del Chatbot

1. **Usuario hace pregunta** â†’ React Frontend
2. **BÃºsqueda en JSON** â†’ Backend busca en reglamento.json (296 entradas)
3. **ConstrucciÃ³n de contexto** â†’ Se extraen las entradas mÃ¡s relevantes
4. **Query a LLM** (si estÃ¡ configurado) â†’ Hugging Face API (AIDC-AI/Marco-LLM-ES)
5. **Respuesta formateada** â†’ Markdown con **negrita**, _cursiva_, listas, etc.
6. **Renderizado** â†’ Frontend con react-markdown

## ğŸ“¡ Endpoints

### `GET /`
InformaciÃ³n general de la API

**Response:**
```json
{
  "mensaje": "ğŸš— API Chatbot Reglamento de TrÃ¡nsito Hermosillo",
  "version": "2.0",
  "entradas_cargadas": 42,
  "llm_habilitado": true,
  "modelo_llm": "AIDC-AI/Marco-LLM-ES",
  "endpoints": {...}
}
```

### `POST /query`
Consultar el reglamento de trÃ¡nsito

**Body:**
```json
{
  "pregunta": "Â¿CuÃ¡l es el lÃ­mite de velocidad en zonas escolares?"
}
```

**Response:**
```json
{
  "respuesta": "**LÃ­mite de velocidad en zonas escolares**\n\nSegÃºn el reglamento...",
  "fuentes": [...],
  "usa_llm": true
}
```

### `GET /health`
Verificar estado del servidor

## ğŸ§ª Pruebas

Pueba la API con curl:

```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"pregunta": "lÃ­mite de velocidad en escuelas"}'
```

O abrir la documentaciÃ³n interactiva en: `http://localhost:8000/docs`

## ï¿½ï¸ Estructura

```
backend/
â”œâ”€â”€ main.py              # AplicaciÃ³n FastAPI
â”œâ”€â”€ reglamento.json      # Base de datos del reglamento
â”œâ”€â”€ requirements.txt     # Dependencias Python
â””â”€â”€ README.md           # Este archivo
```

## ğŸ”§ ConfiguraciÃ³n

### CORS
El backend permite peticiones desde:
- `http://localhost:8080` (Vite dev server)
- `http://localhost:5173` (Vite alternative port)

Para producciÃ³n, actualiza `allow_origins` en `main.py`.

## ğŸ“¦ Modelo LLM (Opcional)

Para usar el modelo de Hugging Face (AIDC-AI/Marco-LLM-ES):

1. Descomenta las dependencias en `requirements.txt`:
```bash
pip install transformers torch accelerate
```

2. Implementa la integraciÃ³n en `main.py` (cÃ³digo base ya incluido)

**Nota:** El modelo requiere ~14GB de RAM y GPU para mejor rendimiento.

## ğŸ› Troubleshooting

### Error: "No se encontrÃ³ reglamento.json"
Verifica que `reglamento.json` estÃ© en la misma carpeta que `main.py`.

### Error: CORS
AsegÃºrate de que el frontend estÃ© corriendo en los puertos permitidos (8080 o 5173).

### Puerto en uso
Si el puerto 8000 estÃ¡ ocupado, usa otro:
```bash
uvicorn main:app --reload --port 8001
```
Y actualiza la URL en el frontend.

## ğŸ“„ Licencia

Este proyecto es parte de HMObility - Safe Streets Initiative.
